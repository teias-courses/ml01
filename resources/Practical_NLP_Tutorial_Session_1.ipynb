{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mR34xULvlcH"
      },
      "source": [
        "# Practical NLP Tutorial: Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcZtCD_JuR9s"
      },
      "source": [
        "## Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbKqUzWduaja"
      },
      "source": [
        "### Tensor Attributes and Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQCRBYJPofBF",
        "outputId": "0d6398df-6484-4e8a-a2a3-27e5ba09bee0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor([[4., 5., 6.]])\n",
            "x.ndim: 2\n",
            "x.shape: torch.Size([1, 3])\n",
            "x.size(): torch.Size([1, 3])\n",
            "x.dtype: torch.float32\n",
            "x.device: cpu\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[4., 5., 6.]])\n",
        "\n",
        "print('x:', x)\n",
        "print('x.ndim:', x.ndim)\n",
        "print('x.shape:', x.shape)\n",
        "print('x.size():', x.size())\n",
        "print('x.dtype:', x.dtype)\n",
        "print('x.device:', x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHa_5ZRtV90Q",
        "outputId": "56457e8f-d497-4da6-aaa0-0135ed4e023d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: tensor([[4, 5, 6]], device='cuda:0')\n",
            "y.dtype: torch.int64\n",
            "y.device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "y = torch.tensor([[4, 5, 6.]], dtype=torch.long, device=torch.device('cuda:0'))\n",
        "print('y:', y)\n",
        "print('y.dtype:', y.dtype)\n",
        "print('y.device:', y.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_fC_ZFLR-Gq",
        "outputId": "41f34ce0-83db-42d4-bbdd-a170efc0a867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_long.dtype: torch.int64\n",
            "x_long.dtype: torch.int64\n"
          ]
        }
      ],
      "source": [
        "x_long = x.to(torch.long)   # to() returns a copy if conversion needed\n",
        "print('x_long.dtype:', x_long.dtype)\n",
        "\n",
        "x_long = x.long()           # alias\n",
        "print('x_long.dtype:', x_long.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpwSrih4ShkQ",
        "outputId": "4d55ac5a-d014-491f-f924-5011de3fd5eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_gpu.device: cuda:0\n",
            "x_gpu.device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "x_gpu = x.to(torch.device('cuda:0'))  # to() returns a copy if conversion needed\n",
        "print('x_gpu.device:', x_gpu.device)\n",
        "\n",
        "x_gpu = x.cuda()                      # alias\n",
        "print('x_gpu.device:', x_gpu.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XREi6llluZ5Z"
      },
      "source": [
        "### Tensor Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuHlXEMrTx6D",
        "outputId": "c509cf3c-f22b-4f52-851d-ed82b65c5804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[4.0, 5.0, 6.0]]"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([[4., 5., 6.]])    # accepts python list\n",
        "\n",
        "print(x.tolist())    # returns python list\n",
        "print(x.numpy())    # returns numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onM_Y7EiT7tN",
        "outputId": "acb120ff-e962-4c64-9d78-12b36f3f7438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y: tensor([[7.]])\n",
            "y.tolist(): [[7.0]]\n",
            "y.item(): 7.0\n"
          ]
        }
      ],
      "source": [
        "y = torch.tensor([[7.]])\n",
        "\n",
        "print('y:', y)\n",
        "print('y.tolist():', y.tolist())\n",
        "print('y.item():', y.item())    # if y has a single value\n",
        "                                # returns that as python number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sjEKoHXVinm"
      },
      "source": [
        "### Calculating gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE84FlhIx7Wh",
        "outputId": "f318489c-adf4-4b65-f8f7-a201c636f936"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 4.], requires_grad=True)"
            ]
          },
          "execution_count": 19,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.tensor([1., 2])\n",
        "W = torch.tensor([3., 4], requires_grad=True)\n",
        "b = torch.tensor([5.], requires_grad=True)\n",
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjJoXWOuYXHl",
        "outputId": "92df3398-4839-4046-af44-78048ae7b781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a: tensor([3., 8.], grad_fn=<MulBackward0>)\n",
            "Y: tensor([ 8., 13.], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "a = X * W\n",
        "print('a:', a)\n",
        "Y = a + b\n",
        "print('Y:', Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNakhfpOzanp",
        "outputId": "3b413500-6934-428b-eb22-dff20147ecae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: tensor(21., grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "loss = Y.sum()\n",
        "print('loss:', loss)\n",
        "\n",
        "loss.backward()   # loss should be a single value\n",
        "                  # to call backward without input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIX52dudan7e",
        "outputId": "a4b84976-f98d-40cd-9f29-4edf4f64ac18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W.grad: tensor([2., 4.])\n",
            "b.grad: tensor([6.])\n"
          ]
        }
      ],
      "source": [
        "print('W.grad:', W.grad)\n",
        "print('b.grad:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3lrd9eeaju_"
      },
      "source": [
        "### Applying gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wNfLGzV31C0"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\n",
        "\n",
        "optimizer = torch.optim.SGD([W, b], lr=0.01)\n",
        "optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1VzfhhL5rDN",
        "outputId": "7e7c64d8-f1f0-42ea-d4c7-424de7e1c857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "updated W: tensor([2.9800, 3.9600], requires_grad=True)\n",
            "updated b: tensor([4.9400], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print('updated W:', W)\n",
        "print('updated b:', b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qgwc0luftxMQ"
      },
      "source": [
        "## Let's Dive Deeper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH0k1XeWkEP7",
        "outputId": "5f3abf7a-7d53-4117-fcec-fb0923d9dfc3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3d249526d0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IplQvf_3t1GE"
      },
      "source": [
        "Links to PyTorch documentations:\n",
        "\n",
        "* [torch.nn](https://pytorch.org/docs/stable/nn.html)\n",
        "* [torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
        "* [torch.optim](https://pytorch.org/docs/stable/optim.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cJpW-twis_4D"
      },
      "outputs": [],
      "source": [
        "#@title Upload `kaggle.json`\n",
        "# We use kaggle library to download dataset directly to colab notebook\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "clear_output()\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-EXHinNbBZF"
      },
      "source": [
        "### N-Gram Language Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gesl7hiwr_yr",
        "outputId": "fbe5636b-079d-4a13-f025-47a8afc38aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "#@title Download and unzip the dataset\n",
        "!kaggle datasets download -d aminghd/large-corpus-of-farsi-poems\n",
        "!unzip large-corpus-of-farsi-poems\n",
        "clear_output()\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK2x0l3_tZgM"
      },
      "outputs": [],
      "source": [
        "with open('hafez_norm.txt', 'r') as f:\n",
        "    hafez_poems = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o4vQLXQti61"
      },
      "outputs": [],
      "source": [
        "hafez_poems = hafez_poems.split()\n",
        "vocab = set(hafez_poems)\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l25KSaPSksf7"
      },
      "outputs": [],
      "source": [
        "CONTEXT_SIZE = 2\n",
        "EMBEDDING_DIM = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoeXKTLKuIUu",
        "outputId": "b9657dd1-d581-424f-82a5-1a5d1b81a5dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['یا', 'الا'], 'ایها'),\n",
              " (['ایها', 'یا'], 'الساقی'),\n",
              " (['الساقی', 'ایها'], 'ادر')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngrams = [\n",
        "    (\n",
        "        [hafez_poems[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
        "        hafez_poems[i]\n",
        "    )\n",
        "    for i in range(CONTEXT_SIZE, len(hafez_poems))\n",
        "]\n",
        "ngrams[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GB2CqbqOlTX3"
      },
      "outputs": [],
      "source": [
        "class NGramLanguageModeler(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "        super(NGramLanguageModeler, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embeddings(inputs).view((1, -1))\n",
        "        out = F.relu(self.linear1(embeds))\n",
        "        out = self.linear2(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCWUUYVdlWaN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32EdCd4flmiV"
      },
      "outputs": [],
      "source": [
        "epoch_pbar = tqdm(range(200))\n",
        "for epoch in epoch_pbar:\n",
        "  total_loss = 0\n",
        "  total_count = 0\n",
        "  step_pbar = tqdm(ngrams, total=len(ngrams))\n",
        "  for context, target in step_pbar:\n",
        "    context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long).to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    log_probs = model(context_idxs)\n",
        "    loss = loss_function(log_probs, torch.tensor([word_to_ix[target]]).to(device))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_count += 1\n",
        "    step_pbar.set_postfix(loss=loss.item(), average_loss=total_loss/total_count)\n",
        "  epoch_pbar.set_postfix(total_loss=total_loss, average_loss=total_loss/total_count)\n",
        "  losses.append(total_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulA3TtCBm1Cu"
      },
      "source": [
        "### Using Pre-Trained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evHqS6bVluDc",
        "outputId": "c9416a30-447a-4f4d-c21a-7451d0d7101d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "#@title Download and unzip the dataset\n",
        "!kaggle datasets download -d jp797498e/twitter-entity-sentiment-analysis\n",
        "!unzip twitter-entity-sentiment-analysis\n",
        "clear_output()\n",
        "print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "S_FGtVwSRQi_",
        "outputId": "b21655a1-9015-4a45-ae0d-777d6f2410d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0c87ac3b-abc5-4ae6-84af-756ad3b96102\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>entity</th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will murder yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>I am coming to the borders and I will kill you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands and i will kill you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im coming on borderlands and i will murder you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2401</td>\n",
              "      <td>Borderlands</td>\n",
              "      <td>Positive</td>\n",
              "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74677</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that the Windows partition of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74678</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized that my Mac window partition is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74679</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized the windows partition of my Mac ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74680</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just realized between the windows partition of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74681</th>\n",
              "      <td>9200</td>\n",
              "      <td>Nvidia</td>\n",
              "      <td>Positive</td>\n",
              "      <td>Just like the windows partition of my Mac is l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>74682 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c87ac3b-abc5-4ae6-84af-756ad3b96102')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c87ac3b-abc5-4ae6-84af-756ad3b96102 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c87ac3b-abc5-4ae6-84af-756ad3b96102');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       tweet_id  ...                                            content\n",
              "0          2401  ...  im getting on borderlands and i will murder yo...\n",
              "1          2401  ...  I am coming to the borders and I will kill you...\n",
              "2          2401  ...  im getting on borderlands and i will kill you ...\n",
              "3          2401  ...  im coming on borderlands and i will murder you...\n",
              "4          2401  ...  im getting on borderlands 2 and i will murder ...\n",
              "...         ...  ...                                                ...\n",
              "74677      9200  ...  Just realized that the Windows partition of my...\n",
              "74678      9200  ...  Just realized that my Mac window partition is ...\n",
              "74679      9200  ...  Just realized the windows partition of my Mac ...\n",
              "74680      9200  ...  Just realized between the windows partition of...\n",
              "74681      9200  ...  Just like the windows partition of my Mac is l...\n",
              "\n",
              "[74682 rows x 4 columns]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('twitter_training.csv', header=None, names=['tweet_id', 'entity', 'label', 'content'])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4uiVrqLSmv3",
        "outputId": "75070f5d-40ee-4490-8afa-aaba2f460e8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Positive', 'Neutral', 'Negative', 'Irrelevant'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.label.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS4PXcjGkIAU"
      },
      "source": [
        "Links to some pretrained embedding models:\n",
        "\n",
        "* [Google Pretrained Embeddings](https://code.google.com/archive/p/word2vec/)\n",
        "* [Word2Vec 400M Tweets Embedding model](https://github.com/loretoparisi/word2vec-twitter)\n",
        "* [Farsi Pretrained Embeddings](https://nlpdataset.ir/farsi/pre-trained_embeddings.html)\n",
        "* [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YcQlKzZmIQ9",
        "outputId": "f3a4690b-ecb2-478f-b0d3-df81b29dfa56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-27 08:57:05--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  1.48MB/s    in 9m 14s  \n",
            "\n",
            "2022-02-27 09:06:20 (1.17 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "#@title Download pretrained model\n",
        "!wget -c \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\"\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qohUYJvSAal2",
        "outputId": "7afdb804-5fa4-40eb-f1bc-8067ab4cdf3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of words 999994\n",
            "# of vectors 999994\n",
            "the first 10 elements of embedding vector for the word king: [ 0.1082  0.0445 -0.0384  0.0011 -0.0888  0.0713 -0.0696 -0.0477  0.0071\n",
            " -0.0408]\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "\n",
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec')\n",
        "\n",
        "print (\"# of words\", len(word2vec.vocab))\n",
        "print (\"# of vectors\", len(word2vec.vectors))\n",
        "print (\"the first 10 elements of embedding vector for the word king:\",\n",
        "       word2vec.vectors[word2vec.vocab[\"king\"].index][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dii5AcwoA7Yi"
      },
      "outputs": [],
      "source": [
        "word2vec.add(['<PAD>'], [np.zeros(300)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60ymmc3-Md-C"
      },
      "outputs": [],
      "source": [
        "word2ix = {k:word2vec.vocab[k].index for k in word2vec.vocab.keys()}\n",
        "ix2word = {v:k for k, v in word2ix.items()}\n",
        "weights = torch.FloatTensor(word2vec.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaawAWsVtdtr"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "\n",
        "class TwitterSentimentAnalysisDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    super(TwitterSentimentAnalysisDataset, self).__init__()\n",
        "    self.df = pd.read_csv('twitter_training.csv', header=None, names=['tweet_id', 'entity', 'label', 'content'])\n",
        "    self.df = self.df.dropna(axis=0, subset=['content', 'label'])\n",
        "    self.df.content = self.df.content.astype('string')\n",
        "    self.label_encoder = preprocessing.LabelEncoder().fit(self.df['label'])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    input = self.df.iloc[index, 3].split()\n",
        "    input = [word2ix[token] for token in input if token in word2ix]\n",
        "    input = [input[i] if i < len(input) else word2ix['<PAD>'] for i in range(32)]\n",
        "\n",
        "    output = self.df.iloc[index, 2]\n",
        "    output = self.label_encoder.transform([output])[0]\n",
        "    \n",
        "    return torch.tensor(input), torch.tensor(output)\n",
        "\n",
        "train_dataset = TwitterSentimentAnalysisDataset('twitter_training.csv')\n",
        "validation_dataset = TwitterSentimentAnalysisDataset('twitter_validation.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVZbODsCH_uE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzw4swwRKJ-X"
      },
      "outputs": [],
      "source": [
        "class TwitterSentimentAnalysisModel(nn.Module):\n",
        "  def __init__(self, embedding_weights):\n",
        "    super(TwitterSentimentAnalysisModel, self).__init__()\n",
        "    self.embedding = nn.Embedding.from_pretrained(embedding_weights)\n",
        "    self.linear1 = nn.Linear(32, 1)\n",
        "    self.linear2 = nn.Linear(300, 100)\n",
        "    self.linear3 = nn.Linear(100, 4)\n",
        "  \n",
        "  def forward(self, inputs):\n",
        "    x = self.embedding(inputs)\n",
        "    x = x.transpose(1, -1)\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = torch.squeeze(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    return F.softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoHGg1NusMGO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "losses = []\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "model = TwitterSentimentAnalysisModel(weights).to(device)\n",
        "model.embedding.weight.required_grad = False\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC6391bq0szs"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "epoch_pbar = tqdm(range(10))\n",
        "for epoch in epoch_pbar:\n",
        "    total_loss = 0\n",
        "    total_count = 0\n",
        "    \n",
        "    model.train()\n",
        "    step_pbar = tqdm(train_dataloader, total=len(train_dataloader))\n",
        "    for content, label in step_pbar:\n",
        "        context_idxs = content.to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "        log_probs = model(context_idxs)\n",
        "        loss = loss_function(log_probs, label.to(device))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_count += 1\n",
        "        step_pbar.set_postfix(loss=loss.item(), average_loss=total_loss/total_count)\n",
        "        \n",
        "        \n",
        "    with torch.no_grad():\n",
        "      validation_loss = 0\n",
        "      validation_count = 0\n",
        "      \n",
        "      y_pred = np.array([])\n",
        "      y_true = np.array([])\n",
        "          \n",
        "      model.eval()\n",
        "      step_pbar = tqdm(validation_dataloader, total=len(validation_dataloader))\n",
        "      step_pbar.set_description(\"Evaluation\")\n",
        "\n",
        "      for content, label in step_pbar:\n",
        "          context_idxs = content.to(device)\n",
        "          log_probs = model(context_idxs)\n",
        "          \n",
        "          y_pred = np.append(y_pred, torch.argmax(log_probs, dim=-1).cpu().numpy())\n",
        "          y_true = np.append(y_true, label.numpy())\n",
        "          loss = loss_function(log_probs, label.to(device))\n",
        "          \n",
        "          validation_loss += loss.item()\n",
        "          validation_count += 1\n",
        "          step_pbar.set_postfix(loss=loss.item())\n",
        "          \n",
        "      \n",
        "      step_pbar.set_postfix(average_loss=validation_loss/validation_count, \n",
        "                            accuracy=metrics.accuracy_score(y_true, y_pred))\n",
        "      step_pbar.update()\n",
        "      step_pbar.close()\n",
        "      \n",
        "      epoch_pbar.set_postfix(total_loss=total_loss, average_loss=total_loss/total_count)\n",
        "      losses.append(total_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrF-JR80L5EY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PyTorch_Tutorial_First_Session.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
