{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical NLP Tutorial - Session 3 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bb0d175b40534238a4762d93e2542863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f6e12dbc3a0407087e259f7ade35768",
              "IPY_MODEL_2d0f07cceed54cbb95ec9ff9f724a90b",
              "IPY_MODEL_0b4741e0a40847a38a8615c1585c004a"
            ],
            "layout": "IPY_MODEL_af6d9caa735a4129b4f1d2daaae1c3e2"
          }
        },
        "5f6e12dbc3a0407087e259f7ade35768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c17f3926ad54e7f9b8ad14ac1a925a0",
            "placeholder": "​",
            "style": "IPY_MODEL_b78efb6e53334cafb8cb6433bb57deb3",
            "value": "100%"
          }
        },
        "2d0f07cceed54cbb95ec9ff9f724a90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4be662865af3477987d3ad74ecb41e2a",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f46621c1eab430291b1af5ec613f2fe",
            "value": 203
          }
        },
        "0b4741e0a40847a38a8615c1585c004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3125fb744447648393f2be40a85c3e",
            "placeholder": "​",
            "style": "IPY_MODEL_94a87da5a22947fca7c37448b7cac03f",
            "value": " 203/203 [00:01&lt;00:00, 141.93ba/s]"
          }
        },
        "af6d9caa735a4129b4f1d2daaae1c3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c17f3926ad54e7f9b8ad14ac1a925a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b78efb6e53334cafb8cb6433bb57deb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4be662865af3477987d3ad74ecb41e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f46621c1eab430291b1af5ec613f2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f3125fb744447648393f2be40a85c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a87da5a22947fca7c37448b7cac03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94690a90862b431a90afeb178d6e7a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69abe00ede5249caaa75ec40429d6980",
              "IPY_MODEL_a8526a9747824e5599382b1c6b958c74",
              "IPY_MODEL_d143f663c1c7462f92c90a5fa917b5e1"
            ],
            "layout": "IPY_MODEL_53596e64336d4c18b3ca674b11c20c2d"
          }
        },
        "69abe00ede5249caaa75ec40429d6980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0461c69138854b808cc2f0b595b31f89",
            "placeholder": "​",
            "style": "IPY_MODEL_aa04b5cefa2c463aa5e59a4961e6c742",
            "value": "100%"
          }
        },
        "a8526a9747824e5599382b1c6b958c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f2087bdca84a0caecf118a720bcf5e",
            "max": 203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fe217f0a27143a286b254b305174fc4",
            "value": 203
          }
        },
        "d143f663c1c7462f92c90a5fa917b5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6e0c022f734450b9d3ae6fd5237e034",
            "placeholder": "​",
            "style": "IPY_MODEL_ca314aced64643e49afe7d2b7b05c134",
            "value": " 203/203 [00:01&lt;00:00, 120.73ba/s]"
          }
        },
        "53596e64336d4c18b3ca674b11c20c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0461c69138854b808cc2f0b595b31f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa04b5cefa2c463aa5e59a4961e6c742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f2087bdca84a0caecf118a720bcf5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe217f0a27143a286b254b305174fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6e0c022f734450b9d3ae6fd5237e034": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca314aced64643e49afe7d2b7b05c134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning a Language Model"
      ],
      "metadata": {
        "id": "yD7PNhhgScvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJSl6LMjBn3n"
      },
      "outputs": [],
      "source": [
        "%pip install transformers tokenizers datasets\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "Aafs1dJGHIb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cardiffnlp/tweeteval.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoBFpsj8CCAR",
        "outputId": "a0d1d066-0e6b-4262-dac7-dae11e131492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tweeteval'...\n",
            "remote: Enumerating objects: 367, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 367 (delta 21), reused 13 (delta 4), pack-reused 318\u001b[K\n",
            "Receiving objects: 100% (367/367), 10.79 MiB | 13.11 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('text', data_files={'train': ['/content/tweeteval/datasets/hate/train_text.txt', \n",
        "                                                     '/content/tweeteval/datasets/hate/test_text.txt', \n",
        "                                                     '/content/tweeteval/datasets/hate/val_text.txt']})\n",
        "\n",
        "clear_output()\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0tngBy7G9-7",
        "outputId": "6a0523d1-9b4e-41c5-8a52-3684a81cf9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 12970\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"roberta-base\" #@param {type:\"string\"}\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "D1VqdLg8H0oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 512 #@param {type:\"integer\"}\n",
        "\n",
        "def tokenize_and_encode(example):\n",
        "  return tokenizer(example[\"text\"], truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_and_encode, batched=True, load_from_cache_file=False, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bb0d175b40534238a4762d93e2542863",
            "5f6e12dbc3a0407087e259f7ade35768",
            "2d0f07cceed54cbb95ec9ff9f724a90b",
            "0b4741e0a40847a38a8615c1585c004a",
            "af6d9caa735a4129b4f1d2daaae1c3e2",
            "3c17f3926ad54e7f9b8ad14ac1a925a0",
            "b78efb6e53334cafb8cb6433bb57deb3",
            "4be662865af3477987d3ad74ecb41e2a",
            "4f46621c1eab430291b1af5ec613f2fe",
            "1f3125fb744447648393f2be40a85c3e",
            "94a87da5a22947fca7c37448b7cac03f"
          ]
        },
        "id": "8_loYjdsIAVy",
        "outputId": "7e67a39b-1732-47cb-ba39-14a87fb3ea54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/203 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb0d175b40534238a4762d93e2542863"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roberta-retrained\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    seed=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset['train']\n",
        ")\n"
      ],
      "metadata": {
        "id": "XMJf-R44IG2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "GzhLAoCTIeu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Model"
      ],
      "metadata": {
        "id": "wDDWjUq5G6tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "RGUsdJYkENnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker1 = pipeline('fill-mask', model=model_name)\n",
        "unmasker2 = pipeline('fill-mask', model='/content/roberta-retrained/checkpoint-12500', tokenizer=model_name)\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "EpLnhWs7G0GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = \"Paris is the <mask> of France.\" #@param {type:\"string\"}\n",
        "top_k =  8#@param {type:\"integer\"}\n",
        "\n",
        "def plot_probs(ax, unmasker, input_sentence, top_k):\n",
        "  result = unmasker(input_sentence, top_k=top_k)\n",
        "\n",
        "  words = list(map(lambda item: item['token_str'], result))\n",
        "  probabilities = list(map(lambda item: item['score'], result))\n",
        "\n",
        "  ax.barh(words, probabilities, height=0.1)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "fig.suptitle('MLM probabilities')\n",
        "plot_probs(ax1, unmasker1, input_sentence, top_k)\n",
        "plot_probs(ax2, unmasker2, input_sentence, top_k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "hjfGQzMnG2-p",
        "outputId": "38d4cde0-f726-4b23-e0f3-4bbec200c6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEVCAYAAAAy15htAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5xVdb3v8debAZXfhoydRHHmeEwFZRC3NHqNQPx59KhhN0otJzOyc7PyXkvIVNR+cLyee85Rb9nUIzET8yR6Ir0RoiBmIg0/DdJjCj4USxFsApQOPz73j71Gt+PMMAPz3XvPzPv5eMzD9eO71vqs7Wfz3mutDaOIwMzMLIVepS7AzMy6L4eMmZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTIOGbMyImm8pJf3cNsqSSGpdyvrvy7phy2NlfRLSRe3se/bJV2zJ3VZz9ZiM5p1NZLWAQcBB0XE6wXLlwOjgeqIWCdpJvByRHyjhX0EsCHbx45sWR9gPVAZEUp+IglFxLfbWHdm07SkOuDSiDipYP1laauz7spXMtadrAU+2TQj6RigXwf38QZwZsH8mdmyTtHaVYZZd+WQse7kLuDTBfMXAz/ey318enf7kLRO0jRJayS9IekOSftl68ZLelnSVZL+BNwhaV9J/yrpleznXyXt22yfX5f0erbvCwuWnyVpuaS/SHpJ0vQWSrok2+8fJV1ZsO10ST9p5RwWSrpU0lHA7cAJkrZI+nO2fqakbxaMP1vSCkl/lvQbSaMK1l0lab2kzZKelTSxrdfPujeHjHUni4FBko6SVAF8AmjxD9U2/AcwTtL+kt4HfBj4eTu2uxA4HTgM+CBQeDvub4AhwKHAFOBqoJb8bbwaYGwL44cCw8gHZb2kI7J1W8kH3/7AWcAXJJ3XrJYJwOHAacBVkk5pR/0ARMTvgcuAJyNiQETs33yMpGOBHwGfBw4Avg/MycLzCOCLwPERMTB7Tda19/jW/ThkrLtpuhI5Ffg9+ecpHbEN+AUwOfuZky3bndsi4qWI2AR8i4LbdsAu4LqI+GtEvEU+kG6IiNciYgNwPfCpZvu7Jhv/GPAQ8HGAiFgYEU9HxK6IWAXcA3yk2bbXR8TWiHgauKNZLZ1hCvD9iHgqInZGxJ3AX8kH505gX2CEpD4RsS4inu/k41sX4pCx7uYu4AKgjo7fKmvyY/JBtdtbZQVeKph+kfyXEJpsiIjCoDooG9Pa+DciYmtL6yV9SNICSRskNZK/6hjagVo6w6HA/8pulf05u6V2CPkvTPwB+AowHXhN0k8ldfbxrQtxyFi3EhEvkv8CwN8D9+/hbh4HPgC8H/h1O7c5pGB6OPBKYVnNxr5C/g/q1sa/T1L/VtbPIn91dUhEDCb//KT5t97aqqU9dvdPs78EfCsi9i/46RcR9wBExKzsm2mHZvv6pw4e37oRh4x1R58FTm52NVCoQtJ+BT/7FK6M/O+/+AfgnGj/78L4H5IOljSE/DOXe9sYew/wDUmVkoYC1/LeZ0fXS9pH0oeBs4GfZcsHApsiYpukseSv2pq7RlI/SSOBz+ymlpa8Chzc/HUp8APgsuyqSpL6Z19IGCjpCEknZ19k2Aa8Rf52ofVQ/jqldTvteAYwNftp8gRwUuGAiFjdwcPOAuaRvzX1c+CbbYz9JjAIWJXN/6zZ+D+R/9r0K8CbwGUR8Uy27h+Bf5Z0G/AY8O/kvwRQ6DHgD+Q/RN4cEfM6eC6PAquBP0naFRHvuh0XEQ2SPgfcRv4LBm+Rv+JbRP55zAzgKGA78Bvyz3Csh5J/aZnZ3sn+IuilETG/1LWYlRvfLjMzs2QcMmZmloxvl5mZWTK+kjEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJOGTMzCwZh4yZmSXjkDEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJ+NcvNzN06NCoqqoqdRnWTS1duvT1iKgs9nHd15ZSW33tkGmmqqqKhoaGUpdh3ZSkF0txXPe1pdRWX/t2mZmZJeOQMTOzZBwyZmaWjEPGzMyScciYmVkyDhkzM0umQyEjaUsry2+QdEor6+okHVQwv07S0A4cs0rS7zpSp1lHDRgwoMXl1157LfPnz29x3cyZM3nllVfenq+qquL1119v9zHd29YTdMrfk4mIa1taLqkCqAN+B7zS0hizcnbDDTe0uHznzp3MnDmTo48+moMOOqjFMWa2B7fLJP2LpNWSHpFUmS2bKelj2fQ6Sf8kaRnwSSAH3C1phaS+2W4ul7RM0tOSjsy2my7pLklPSnpO0udaOHaVpMezbZdJOrFg3VXZ/lZKmpEtO0zSXElLs+2O7Oj5Ws9xxRVXMHLkSCZOnMiGDRsAqKur47777gPyVypXXXUVY8aM4Z577qGhoYELL7yQ0aNH89ZbbwFw6623MmbMGI455hieeeYZAKZPn86nPvUpTjjhBICjS9HbT69v7IyXyKzDOhoy/YGGiBgJPAZc18q4jRExJiJ+AjQAF0bE6Ih4K1v/ekSMAb4HXFmw3SjgZOAE4NrC22yZ14BTs20nA7cASDoTOBf4UETUADdl4+uByyPiuOw43+3g+VoPsXXrVnK5HKtXr+YjH/kI119/fYvjDjjgAJYtW8ZFF11ELpfj7rvvZsWKFfTtm//8NHToUJYtW8YXvvAFbr755re3W7VqFY8++ijAM7i3rQfp6O2yXcC92fRPgPtbGXdvK8ubNG23FJhUsPznWRC9JWkBMBZYUbC+D3CbpNHATuCD2fJTgDsi4k2AiNgkaQBwIvAzSU3b79tSMZKmAFMAhg8fvpvSrTvq1asXkydPBuCiiy5i0qRJLY5rGtOapu2OO+447r//nbfHueee2xREO4Ci9HZhX1cMKvo/l2YG7P0zmWhl+dbdbPfX7L87m9XQfH/N568AXgVqyF+FbWvjGL2AP0fE6N3UQkTUk/9kSC6Xa+2crAcp+MP7Xfr379/mdvvum/+zvqKigh07drS1v+S97b62ctDR22W9gI9l0xcAv27HNpuBge3c/7mS9pN0ADAe+G2z9YOBP0bELuBTQEW2/GHgM5L6AUgaEhF/AdZK+u/ZMkmqaWcd1sPs2rXr7Wcvs2bN4qSTTtrtNgMHDmTz5s3t2v/Pf/5ztm3bBvmeHY9723qIjobMVmBs9rXLk4GWv3rzbjOB25s9+G/NKvK3EhYDN0ZE82+kfRe4WNJK4MisHiJiLjAHaJC0gnee81wIfDYbv5r8vW2z9+jfvz9Llizh6KOP5tFHH+Xaa1v8wuS71NXVcdlll73rwX9rRo0axYQJEwCOwr1tPYgiyuMqWtJ0YEtE3Ly7sSnlcrnwP4lunWn69OkMGDCAK6+8EklLIyJX7Brc15ZSW33tv/FvZmbJlM0vLYuI6aWuwSyF6dOnl7oEs5LxlYyZmSXjkDEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJOGTMzCwZh4yZmSXjkDEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJOGTMzCwZh4yZmSXT5UNG0tdLXYNZZ3NfW3fR5UMGaPHNqLzucH7WM7mvrVsoWbNKOkPSMkkrJT2SLesv6UeSlkhaLuncbHmdpPslzZX0nKSbsuUzgL6SVki6W1KVpGcl/Rj4HXCIpK9K+q2kVZKuL9X5Ws8wd+5cxowZQ01NDRMnTgRg69atXHLJJYwdOxZgRCn6+un1jalO2axtEVH0H6ASeAmozuaHZP/9NnBRNr0/8J9Af6AOeAEYDOwHvAgcko3bUrDfKmAXUJvNnwbUAyIfqA8C41qoZwrQADQMHz48zPbEa6+9FgcffHC88MILERGxcePGiIiYNm1a3HXXXRERASwvRV9XDKos+uthPQfQEK38eV+qK5laYFFErAWIiE3Z8tOAqZJWAAvJv/GGZ+seiYjGiNgGrAEObWXfL0bE4oL9nUb+jb0MOBI4vPkGEVEfEbmIyFVWVu71yVnPtHjxYsaNG0d1dTUAQ4YMAWDevHnMmDGD0aNHAxxBCfq6ot/gzjhFsw7rXeoCmhFwfkQ8+66F0oeAvxYs2knrtW9ttr/vRMT3O7VKsw6ICGbPns0RRxyBpDURkYPi9vUxwxwyVhqlupJZDIyTVA0gaUi2/FfA5ZKULT+2HfvaLqlPK+t+BVwiaUC2v2GSDty70s1aVltby6JFi1i7di0AmzblL9BPP/10br311qZbWO5r61FKEjIRsYH8/eL7Ja0E7s1W3Qj0AVZJWp3N7059Nv7uFo4zD5gFPCnpaeA+YGAnnILZe1RWVlJfX8+kSZOoqalh8uTJAFxzzTVs376dUaNGAYzEfW09iJo+XVleLpeLhoaGUpdh3ZSkpU23y4rJfW0ptdXX/r69mZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTIOGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTIOGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpbMHoWMpC2dXUi23ypJFxTM10m6rZP2/RVJ/TpjX9Y9DRgwIMl+161bx6xZs96ed19bT1I2VzKSegNVwAW7GbqnvgL4zWhFtWPHjveETCdzX1tZ2+OQkfQtSSslLZb0/mxZpaTZkn6b/fy3bPlYSU9KWi7pN5KOyJbXSZoj6VHgEWAG8GFJKyRdkR3qEEkLJT0n6bqC418kaUk29vuSKrLl35PUIGm1pOuzZV8CDgIWSFqwp+ds3d/VV19NTU0NtbW1vPrqqwBs2LCB888/n+OPP57jjz+eJ554AoAlS5ZwwgkncOyxx3LiiSfy7LPPAjBz5kzOOeccTj75ZCZOnMjUqVN5/PHHGT16NMCB2aGK2tdPr2/szJfJrP0iosM/QAD/kE3fBHwjm54FnJRNDwd+n00PAnpn06cAs7PpOuBlYEg2Px54sOA4dcAfgQOAvsDvgBxwFPALoE827rvAp7Pppn1VAAuBUdn8OmBoK+czBWgAGoYPHx7WMwExZ86ciIj46le/GjfeeGNERHzyk5+Mxx9/PCIiXnzxxTjyyCMjIqKxsTG2b98eEREPP/xwTJo0KSIi7rjjjhg2bFhs3LgxIiIWLFgQZ511VtMxGkrR1xWDKpO/ftZzAQ3RSl707kAeFfov4MFseilwajZ9CjBCUtO4QZIGAIOBOyUdTj6g+hTs6+GI2NTGsR6OiI0Aku4HTgJ2AMcBv82O1Rd4LRv/cUlTgN7AB4ARwKq2TiYi6oF6gFwuF22Nte5rn3324eyzzwbguOOO4+GHHwZg/vz5rFmz5u1xf/nLX9iyZQuNjY1cfPHFPPfcc0hi+/btb4859dRTGTJkSFuHK2pf7/uBw93XVhJ7GjLbs/QC2Fmwn15AbURsKxycPeRcEBEflVRF/pNYk627OVbzN0cAAu6MiGnNjlMNXAkcHxFvSJoJ7NeeEzLr06cPTR+QKioq2LFjBwC7du1i8eLF7Lffu1vpi1/8IhMmTOCBBx5g3bp1jB8//u11/fv3393hitrXxwwb3JHhZp2msx/8zwMub5qRNDqbHAysz6br2th+MzCw2bJTJQ2R1Bc4D3iC/PObj0k6MDvOEEmHkr8ttxVozJ4TnbmbfZvt1mmnncatt9769vyKFSsAaGxsZNiwYUD+OUxrBg4cyObNm5svdl9bj9DZIfMlICdplaQ1wGXZ8puA70haTttXT6uAndkXCpoe/C8BZmfrZkdEQ0SsAb4BzJO0CngY+EBErASWA8+Qfz70RMG+64G5fvBvHXXLLbfQ0NDAqFGjGDFiBLfffjsAX/va15g2bRrHHnvs21c9LRk1ahQVFRXU1NTAOw/+3dfWI+idu14G+WcyDQ0NpS7DuilJSyMiV+zjuq8tpbb6umz+noyZmXU/DhkzM0vGIWNmZsk4ZMzMLBmHjJmZJeOQMTOzZBwyZmaWjEPGzMyScciYmVkyDhkzM0vGIWNmZsk4ZMzMLBmHjJmZJeOQMTOzZBwyZmaWjEPGzMyScciYmVkyDhkzM0vGIWNmZsl0+ZCRdI6kqdn0eZJGlLoms87g3rbuoMuHTETMiYgZ2ex5gN+I1i24t6076FIhI+kMScskrZT0SLasTtJtkk4EzgH+t6QVkg6TtKxg28ML583KSerefnp9Y9oTMGtF71IX0F6SKoEfAOMiYq2kIYXrI+I3kuYAD0bEfdk2jZJGR8QK4DPAHa3sewowBWD48OEpT8PsPVL1dmFfVwyqTH0aZi3qSlcytcCiiFgLEBGb2rHND4HPSKoAJgOzWhoUEfURkYuIXGWl34xWdEl6u7CvK/oN7tSCzdqrK4XMnpgNnAmcDSyNiI0lrsess3Sot48Z5pCx0uhKIbMYGCepGqD5LYXMZmBg00xEbAN+BXyPVm6VmZUB97Z1W10mZCJiA/n7y/dLWgnc28KwnwJflbRc0mHZsruBXcC84lRq1jHubevOusyDf4CI+CXwy2bLZgIzs+kneO/XPE8C7oiInUUo0WyPuLetu+pSIdNRkh4ADgNOLnUtZp3JvW1dRbcOmYj4aKlrMEvBvW1dRZd5JmNmZl2PQ8bMzJJxyJiZWTIOGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTIOGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpZMlw4ZSV8vdQ1mKbi3rbvo0iEDdPiNKKkiRSFmncy9bd1CSUJG0hmSlklaKemRbFl/ST+StETScknnZsvrJN0vaa6k5yTdlC2fAfSVtELS3dmyi7LtV0j6ftObTtIWSf8saSVwQlu1Pb2+kaqpD6U8fevG5s6dy5gxY6ipqWHixIkAbN26lUsuuYSxY8cCjChFbzf1tXvbii4iivoDVAIvAdXZ/JDsv98GLsqm9wf+E+gP1AEvAIOB/YAXgUOycVsK9nsU8AugTzb/XeDT2XQAH2+jpilAA9BQMagyDr3qwTDrqNdeey0OPvjgeOGFFyIiYuPGjRERMW3atLjrrrsiIgJYXqzebqmv3duWAtAQrfz52rsTcqqjaoFFEbEWICI2ZctPA86RdGU2vx8wPJt+JCIaASStAQ4lH1SFJgLHAb+VBNAXeC1btxOY3VpBEVEP1APkcrlomHHWHp+c9VyLFy9m3LhxVFdXAzBkyBAA5s2bx5w5c7j55psBjgBepwi97b62clCKkGmNgPMj4tl3LZQ+BPy1YNFOWq5bwJ0RMa2FddsiYmenVWrWARHB7NmzOeKII5C0JiJy4N62nqEUz2QWA+MkVQNIGpIt/xVwubKPapKObce+tkvqk00/AnxM0oFN+5V0aOeWbta62tpaFi1axNq1awHYtCl/kX766adz6623Nt3Ccm9bj1L0kImIDeTvFd+fPay8N1t1I9AHWCVpdTa/O/XZ+LsjYg3wDWCepFXAw8AHOv0EzFpRWVlJfX09kyZNoqamhsmTJwNwzTXXsH37dkaNGgUwEve29SBq+nRleblcLhoaGkpdhnVTkpY23S4rJve1pdRWX3f1vydjZmZlzCFjZmbJOGTMzCwZh4yZmSXjkDEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJOGTMzCwZh4yZmSXjkDEzs2QcMmZmloxDxszMknHImJlZMg4ZMzNLxiFjZmbJFDVkJA2Q9H1Jz0taKmmhpA/t4b5ukHRKNv0VSf3asc1CSUX/1bfWvW3ZsoXPf/7zHHbYYRx33HGMHz+ep556ao/25b627qZ3kY/3Q2AtcHhE7JJUDYzYkx1FxLUFs18BfgK8ufclmnXMpZdeSnV1Nc899xy9evVi7dq1rFmzZo/25b627qZoISPpMOBDwIURsQsgItaSDx0k/QdwCLAf8G8RUZ8t3wL8ADgN+BPwiYjYIGkm8CBwUPazQNLrETFB0veA44G+wH0RcV1763x6fSNVUx96e37djLP26ryte3v++ed56qmnuPvuu+nVK39joLq6murqagDOO+88XnrpJbZt28aXv/zlt7crdV+De9uKo5i3y0YCKyJiZyvrL4mI44Ac8CVJB2TL+wMNETESeAx41xsrIm4BXgEmRMSEbPHVEZEDRgEfkTSqk8/FDIDVq1czevRoKioqWlz/ox/9iKVLl9LQ0MAtt9wC0DTQfW09Qjk9+P+SpJXAYvJXNIdny3cB92bTPwFOase+Pi5pGbCcfLi1eUtO0hRJDZIadr7ZuEfFm7XklltuoaamhtraWl566SXIX6mD+9p6iGI+k1kN1EiqaH41I2k8cApwQkS8KWkh77wZm4u2DpI957kSOD4i3shuP7S2r/wO87fm6gFyuVw0+DaCtdPIkSNZuXIlO3fufM/VzMKFC5k/fz5PPvkk/fr1Y/z48Tz22GOtfbBzX1u3VLQrmYh4HmgArpckAElVks4CBgNvZAFzJFDbrMaPZdMXAL9uYfebgYHZ9CBgK9Ao6f3AmZ1+MmaZww47jFwux3XXXUdEPifWrVvHQw89RGNjI+973/vo168fzzzzDIsXLy7c1H1tPUKxb5ddCrwf+IOk3wEzgdeAuUBvSb8HZpC/ZdZkKzA2G38ycEML+60H5kpaEBEryd9OeAaYBTyR6FzMAPjhD3/Iq6++yt/93d9x9NFHU1dXx4EHHsgZZ5zBjh07OOqoo5g6dSq1tYWfndzX1jOo6dNXuZK0JSIGFOt4uVwuGhoainU462EkLY2InPvaupOmvm5pXTk9+Dczs26m7EOmmJ/2zIrFfW09RdmHjJmZdV0OGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTIOGTMzS8YhY2ZmyThkzMwsGYeMmZkl45AxM7NkHDJmZpaMQ8bMzJJxyJiZWTJlFTKStiTab5WkC1Ls26w9BgxI84sw3dtW7soqZFKQ1BuoAvxGtG7FvW1dQe9SF9CcpG8BZwNvAedGxKuSKoHbgeHZsK9ExBOSxgL/BuyXjf9MRDwrqQ6YBAwAKoB9gaMkrQDujIh/ae34T69vpGrqQ23WuG7GWXtzitZDXX311QAjJC2myL3dnr4G97Z1vnILmf7A4oi4WtJNwOeAb5J/s/1LRPxa0nDgV8BRwDPAhyNih6RTgG8D52f7GgOMiohNksYDV0bE2UU+HzMAtm7dSm1tLcAaYBHubeshyi1k/gt4MJteCpyaTZ9C/hNg07hBkgYAg4E7JR0OBNCnYF8PR8Sm9hxU0hRgCkDFoMq9OgGzluyzzz6cffbbOVCU3nZfWzkot5DZHhGRTe/knfp6AbURsa1wsKTbgAUR8VFJVcDCgtVb23vQiKgH6gFyuVw0+JaBdbI+ffpQECRF6W33tZWDrvLgfx5wedOMpNHZ5GBgfTZd18b2m4GBSSoz2zvubevWukrIfAnISVolaQ1wWbb8JuA7kpbT9lXZKmCnpJWSrkhcq1lHuLetW9M7d6cMstsKDQ2lLsO6KUlLIyJX7OO6ry2ltvq6q1zJmJlZF+SQMTOzZBwyZmaWjEPGzMyScciYmVkyDhkzM0vGIWNmZsk4ZMzMLBmHjJmZJeOQMTOzZBwyZmaWjEPGzMyScciYmVkyDhkzM0vGIWNmZsk4ZMzMLBmHjJmZJeOQMTOzZBwyZmaWTJcNGUm/yf5bJemCdoyvkvS79JWZ7R33tnUnXTZkIuLEbLIK2O0b0ayrcG9bd9K72AeUdAbwbaACeD0iJkoaC/wbsB/wFvCZiHhWUh3wUWAwMAz4SURcn+1nS0QMAGYAR0laAdwJPADcBfTPDvnFiPhNe+t7en0jVVMf6oQztZ7mrReW8udFP+bI9/dn6NChPPLIIyxZsoQvf/nLbNu2jb59+wLsC1Ds3nZf295aN+OsPdquqCEjqRL4ATAuItZKGpKtegb4cETskHQK+RA6P1s3FjgaeBP4raSHIqKhYLdTgSsj4uzsGP2AUyNim6TDgXuAXPKTsx5t55uNbJx7K++/YAYrb/8smzZtAuDII4/k8ccfp3fv3syfP59TTz314ILN3NvW7RX7SqYWWBQRawEiYlO2fDBwZ/bGCaBPwTYPR8RGAEn3AycBhW/E5voAt0kaDewEPri7oiRNAaYAVAyq7NAJmQH89ZVn2PeQkfTZ/28AGDIk//mpsbGRiy++mOeeew5JkL9ab5K0t93XVg6KfrusFTcCCyLio5KqgIUF66LZ2ObzzV0BvArUkH/mtG13B4+IeqAeIJfLRcMeXhZaz/WLX+zipz99nrub9c4111zDhAkTeOCBB1i3bh3V1dWFz0GT9rb72spBsR/8LwbGSaoGKLhdNhhYn03XNdvmVElDJPUFzgOeaLZ+MzCwYH4w8MeI2AV8ivyzH7OkamtrWbRoEWvXrgV4+3ZZY2Mjw4YNA2DmzJnNN3NvW7dX1JCJiA3kL9/vl7QSuDdbdRPwHUnLee/V1RJgNrAKmN3snjXZ8p2SVkq6AvgucHG2/yOBrWnOxuwdlZWV1NfXM2nSJGpqapg8eTIAX/va15g2bRrHHnssO3bsaL6Ze9u6PUXs7gq9dLJv4OQi4ovFOmYul4uGhrZui5vtOUlLIyJX7N52X1tKTX3d0rou+/dkzMys/JXLg/8WRcRMYGaJyzDrdO5t6yl8JWNmZsk4ZMzMLBmHjJmZJeOQMTOzZMr6K8ylIGkz8GyJyxgKvF7iGqA86iiHGqDz6jg0Ior+b7yUSV9Defz/LIcaoHvV0Wpfl/W3y0rk2da+710skhpKXUO51FEONZRTHXuh5H0N5fE6lkMNPakO3y4zM7NkHDJmZpaMQ+a96ktdAOVRA5RHHeVQA5RPHXuqXOovhzrKoQboIXX4wb+ZmSXjKxkzM0umR4aMpDMkPSvpD5KmtrB+X0n3Zuufyn6RWinq+J+S1khaJekRSYeWoo6CcedLCkmd/k2U9tQg6ePZ67Fa0qzOrqE9dUgaLmmBpOXZ/5e/T1HHnnJvt7+GgnHJ+rq9daTu7ZL2dUT0qB/yv+jpeeBvgX2AlcCIZmP+Ebg9m/4EcG+J6pgA9Mumv0IoVnkAAAKbSURBVFCqOrJxA4FF5H/xXK4Er8XhwHLgfdn8gSX6f1IPfCGbHgGsK0Uf70X9PaK3y6GvO/BaJO3tUvd1T7ySGQv8ISJeiIj/An4KnNtszLnAndn0fcBEZb+gvZh1RMSCiHgzm10MHNzJNbSrjsyNwD/Rjl9nnaiGzwH/NyLeAIiI10pURwCDsunBwCsJ6thT7u0O1JBJ2dftrSN1b5e0r3tiyAwDXiqYfzlb1uKYiNgBNAIHlKCOQp8FftnJNbSrDkljgEMi4qEEx29XDcAHgQ9KekLSYklnlKiO6cBFkl4G/h9weYI69pR7uwM1FKGv21UH6Xu7pH3tv/HfBUi6CMgBHynBsXsB/weoK/axm+lN/rbCePKfehdJOiYi/lzkOj4JzIyIf5Z0AnCXpKMjYleR6+gWStXbZdTXUB69nayve+KVzHrgkIL5g7NlLY6R1Jv85ePGEtSBpFOAq4FzIuKvnVxDe+oYCBwNLJS0DqgF5nTyQ9L2vBYvA3MiYntErAX+k/wbszO1p47PAv8OEBFPAvuR/7efyoF7u/01FKOv21MHpO/t0vZ1Zz/oKvcf8p8aXgCqeech2MhmY/4H7344+u8lquNY8g/sDi/l69Fs/EI6/8F/e16LM4A7s+mh5C//DyhBHb8E6rLpo8jfu1Yxe3gv6+8RvV0Ofd2B1yJpb5e6r5M2fbn+AH9P/tPC88DV2bIbyH+ignyK/wz4A7AE+NsS1TEfeBVYkf3MKUUdzcamejPu7rUQ+dsba4CngU+U6P/JCOCJ7I26Ajit1P3cwfp7TG+XQ1+387VI3tul7Gv/jX8zM0umJz6TMTOzInHImJlZMg4ZMzNLxiFjZmbJOGTMzCwZh4yZmSXjkDEzs2QcMmZmlsz/BzeHmkBQPrV0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Behaviours in Trainer API"
      ],
      "metadata": {
        "id": "D88lh2ypSk_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers.tokenization_utils_base import BatchEncoding, PreTrainedTokenizerBase\n",
        "from transformers.models.bert import BertTokenizer, BertTokenizerFast\n",
        "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "nIspWHbjoODB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8241f1f9-4c2e-4db9-fe6b-b989402ab7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _torch_collate_batch(examples, tokenizer, pad_to_multiple_of: Optional[int] = None):\n",
        "    \"\"\"Collate `examples` into a batch, using the information in `tokenizer` for padding if necessary.\"\"\"\n",
        "    import numpy as np\n",
        "    import torch\n",
        "\n",
        "    # Tensorize if necessary.\n",
        "    if isinstance(examples[0], (list, tuple, np.ndarray)):\n",
        "        examples = [torch.tensor(e, dtype=torch.long) for e in examples]\n",
        "\n",
        "    length_of_first = examples[0].size(0)\n",
        "\n",
        "    # Check if padding is necessary.\n",
        "\n",
        "    are_tensors_same_length = all(x.size(0) == length_of_first for x in examples)\n",
        "    if are_tensors_same_length and (pad_to_multiple_of is None or length_of_first % pad_to_multiple_of == 0):\n",
        "        return torch.stack(examples, dim=0)\n",
        "\n",
        "    # If yes, check if we have a `pad_token`.\n",
        "    if tokenizer._pad_token is None:\n",
        "        raise ValueError(\n",
        "            \"You are attempting to pad samples but the tokenizer you are using\"\n",
        "            f\" ({tokenizer.__class__.__name__}) does not have a pad token.\"\n",
        "        )\n",
        "\n",
        "    # Creating the full tensor and filling it with our data.\n",
        "    max_length = max(x.size(0) for x in examples)\n",
        "    if pad_to_multiple_of is not None and (max_length % pad_to_multiple_of != 0):\n",
        "        max_length = ((max_length // pad_to_multiple_of) + 1) * pad_to_multiple_of\n",
        "    result = examples[0].new_full([len(examples), max_length], tokenizer.pad_token_id)\n",
        "    for i, example in enumerate(examples):\n",
        "        if tokenizer.padding_side == \"right\":\n",
        "            result[i, : example.shape[0]] = example\n",
        "        else:\n",
        "            result[i, -example.shape[0] :] = example\n",
        "    return result\n",
        "\n",
        "def tolist(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    elif hasattr(x, \"numpy\"):  # Checks for TF tensors without needing the import\n",
        "        x = x.numpy()\n",
        "    return x.tolist()"
      ],
      "metadata": {
        "id": "65tUdZYVoQAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForLMBasedOnPOSTag(DataCollatorForLanguageModeling):\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        if isinstance(examples[0], (dict, BatchEncoding)):\n",
        "            input_ids = [e[\"input_ids\"] for e in examples]\n",
        "        else:\n",
        "            input_ids = examples\n",
        "            examples = [{\"input_ids\": e} for e in examples]\n",
        "\n",
        "        batch_input = _torch_collate_batch(input_ids, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "\n",
        "        mask_labels = []\n",
        "        for e in examples:\n",
        "            ref_tokens = []\n",
        "            for id in tolist(e[\"input_ids\"]):\n",
        "                token = self.tokenizer._convert_id_to_token(id)\n",
        "                ref_tokens.append(token)\n",
        "            \n",
        "            # print(nltk.word_tokenize(tokenizer.decode(e[\"input_ids\"], skip_special_tokens=True)))\n",
        "            pos_tags = list(map(lambda x: x[1], nltk.pos_tag(nltk.word_tokenize(tokenizer.decode(e[\"input_ids\"], skip_special_tokens=True)))))\n",
        "\n",
        "            mask_labels.append(self._whole_word_mask(ref_tokens, pos_tags))\n",
        "\n",
        "        batch_mask = _torch_collate_batch(mask_labels, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
        "        inputs, labels = self.torch_mask_tokens(batch_input, batch_mask)\n",
        "        return {\"input_ids\": inputs, \"labels\": labels}\n",
        "\n",
        "    def _whole_word_mask(self, input_tokens: List[str], pos_tags: List[str], max_predictions=512):\n",
        "        \"\"\"\n",
        "        Get 0/1 labels for masked tokens with whole word mask proxy\n",
        "        \"\"\"\n",
        "        if not isinstance(self.tokenizer, (BertTokenizer, BertTokenizerFast)):\n",
        "            warnings.warn(\n",
        "                \"DataCollatorForWholeWordMask is only suitable for BertTokenizer-like tokenizers. \"\n",
        "                \"Please refer to the documentation for more information.\"\n",
        "            )\n",
        "\n",
        "        # mlm_tag_list = ['JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNS']\n",
        "        mlm_tag_list = ['JJ', 'JJR', 'JJS']\n",
        "\n",
        "        cand_indexes = []\n",
        "        index = -1\n",
        "\n",
        "        print(pos_tags)\n",
        "        print(input_tokens)\n",
        "        \n",
        "        for (i, token) in enumerate(input_tokens):\n",
        "            if token == \"[CLS]\" or token == \"[SEP]\" or token == \"[PAD]\":\n",
        "                continue\n",
        "\n",
        "            if token.startswith(\"##\"):\n",
        "                if pos_tags[index] in mlm_tag_list:\n",
        "                    cand_indexes[-1].append(i)\n",
        "            else:\n",
        "                index += 1\n",
        "                if pos_tags[index] in mlm_tag_list:\n",
        "                    cand_indexes.append([i])\n",
        "            \n",
        "            print(cand_indexes)\n",
        "\n",
        "        print(cand_indexes)\n",
        "\n",
        "        raise Exception\n",
        "\n",
        "        random.shuffle(cand_indexes)\n",
        "        num_to_predict = min(max_predictions, max(1, int(round(len(input_tokens) * self.mlm_probability))))\n",
        "        masked_lms = []\n",
        "        covered_indexes = set()\n",
        "        for index_set in cand_indexes:\n",
        "            if len(masked_lms) >= num_to_predict:\n",
        "                break\n",
        "            # If adding a whole-word mask would exceed the maximum number of\n",
        "            # predictions, then just skip this candidate.\n",
        "            if len(masked_lms) + len(index_set) > num_to_predict:\n",
        "                continue\n",
        "            is_any_index_covered = False\n",
        "            for index in index_set:\n",
        "                if index in covered_indexes:\n",
        "                    is_any_index_covered = True\n",
        "                    break\n",
        "            if is_any_index_covered:\n",
        "                continue\n",
        "            for index in index_set:\n",
        "                covered_indexes.add(index)\n",
        "                masked_lms.append(index)\n",
        "\n",
        "        if len(covered_indexes) != len(masked_lms):\n",
        "            raise ValueError(\"Length of covered_indexes is not equal to length of masked_lms.\")\n",
        "        mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\n",
        "        return mask_labels\n",
        "\n",
        "    def torch_mask_tokens(self, inputs: Any, mask_labels: Any) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set\n",
        "        'mask_labels' means we use whole word mask (wwm), we directly mask idxs according to it's ref.\n",
        "        \"\"\"\n",
        "        import torch\n",
        "\n",
        "        if self.tokenizer.mask_token is None:\n",
        "            raise ValueError(\n",
        "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\n",
        "            )\n",
        "        labels = inputs.clone()\n",
        "        # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "\n",
        "        probability_matrix = mask_labels\n",
        "\n",
        "        special_tokens_mask = [\n",
        "            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\n",
        "        ]\n",
        "        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        "        if self.tokenizer._pad_token is not None:\n",
        "            padding_mask = labels.eq(self.tokenizer.pad_token_id)\n",
        "            probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
        "\n",
        "        masked_indices = probability_matrix.bool()\n",
        "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\n",
        "\n",
        "        # 10% of the time, we replace masked input tokens with random word\n",
        "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
        "        inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "        return inputs, labels"
      ],
      "metadata": {
        "id": "BzSbsV06SpmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-uncased\" #@param {type:\"string\"}\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "7RWdSHNxN2Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 512 #@param {type:\"integer\"}\n",
        "\n",
        "def tokenize_and_encode(example):\n",
        "  return tokenizer(example[\"text\"], truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_and_encode, batched=True, load_from_cache_file=False, batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "94690a90862b431a90afeb178d6e7a67",
            "69abe00ede5249caaa75ec40429d6980",
            "a8526a9747824e5599382b1c6b958c74",
            "d143f663c1c7462f92c90a5fa917b5e1",
            "53596e64336d4c18b3ca674b11c20c2d",
            "0461c69138854b808cc2f0b595b31f89",
            "aa04b5cefa2c463aa5e59a4961e6c742",
            "45f2087bdca84a0caecf118a720bcf5e",
            "3fe217f0a27143a286b254b305174fc4",
            "c6e0c022f734450b9d3ae6fd5237e034",
            "ca314aced64643e49afe7d2b7b05c134"
          ]
        },
        "id": "mcJN_9coPfsH",
        "outputId": "661f8f77-f1f7-4621-ad2f-570b2a73ebb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/203 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94690a90862b431a90afeb178d6e7a67"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLMBasedOnPOSTag(tokenizer=tokenizer, mlm=True, mlm_probability=0.8)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-retrained\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=25,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    seed=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset['train']\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZWBXVy6Lovqt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6dfad4-79eb-4a20-8a9c-c736f825618e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "qXnKkhHBowlf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "outputId": "8c33ea59-d0f3-43f9-9d4e-8e06aa0902d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: text. If text are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 12970\n",
            "  Num Epochs = 25\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 162125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['VBG', 'JJ', 'NNS', 'VBZ', 'RB', 'DT', 'CD', ':', 'NN', 'NN']\n",
            "['[CLS]', 'det', '##ain', '##ing', 'immigrant', 'kids', 'is', 'now', 'a', 'billion', '-', 'dollar', 'industry', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n",
            "[[4]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-46385b557e54>\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mmask_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_whole_word_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_torch_collate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-46385b557e54>\u001b[0m in \u001b[0;36m_whole_word_mask\u001b[0;34m(self, input_tokens, pos_tags, max_predictions)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcand_indexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IgW0LC53SPiP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}